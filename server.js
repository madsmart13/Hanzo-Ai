// server.js
import express from "express";
import fetch from "node-fetch"; // Ø§Ú¯Ø± Node >=18 Ù…ÛŒØ´Ù‡ Ø§Ø² global fetch Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù‚Ø·Ø¹ÛŒ node-fetch Ø±Ø§Ø­Øª Ø§Ø³Øª
import cors from "cors";
import dotenv from "dotenv";

dotenv.config();

const app = express();
app.use(cors());
app.use(express.json({ limit: "1mb" }));

const PORT = process.env.PORT || 3000;
const OPENAI_KEY = process.env.OPENAI_API_KEY;

if (!OPENAI_KEY) {
  console.error("âŒ Ù„Ø·ÙØ§Ù‹ OPENAI_API_KEY Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ .env Ù‚Ø±Ø§Ø± Ø¨Ø¯Ù‡.");
  process.exit(1);
}

// Ù…Ø³ÛŒØ± ØªØ³Øª Ø³Ø§Ø¯Ù‡
app.get("/test", (req, res) => {
  res.send("Server OK");
});

// Ù…Ø³ÛŒØ± Ø§Ø³ØªØ±ÛŒÙ…: Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù… Ø§Ø² ÙØ±Ø§Ù†Øª -> ÙÙˆØ±ÙˆØ§Ø±Ø¯ Ø¨Ù‡ OpenAI (stream: true) -> ÙØ±Ø³ØªØ§Ø¯Ù† chunks Ø¨Ù‡ Ú©Ù„Ø§ÛŒÙ†Øª
app.post("/ask", async (req, res) => {
  try {
    const { message } = req.body;
    if (!message) return res.status(400).json({ error: "message missing" });

    // Ø¨Ù‡ Ú©Ù„Ø§ÛŒÙ†Øª Ù…ÛŒâ€ŒÚ¯ÙˆÛŒÛŒÙ… Ø§ÛŒÙ† Ù¾Ø§Ø³Ø® Ø¨Ù‡ ØµÙˆØ±Øª stream Ù…ÛŒâ€ŒØ¢ÛŒØ¯:
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");

    // Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ OpenAI
    const r = await fetch("https://api.openai.com/v1/responses", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${OPENAI_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: "gpt-4.1-mini",   // Ù‡Ø± Ù…Ø¯Ù„ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒ
        input: message,
        stream: true
      }),
    });

    if (!r.ok) {
      const errText = await r.text();
      console.error("OpenAI error:", r.status, errText);
      res.write(`data: ${JSON.stringify({ error: "openai_error", status: r.status, body: errText })}\n\n`);
      return res.end();
    }

    const reader = r.body.getReader();
    const decoder = new TextDecoder();

    // ÙˆÙ‚ØªÛŒ Ø¯Ø§Ø¯Ù‡ Ø§Ø² OpenAI Ù…ÛŒâ€ŒØ¢ÛŒØ¯ØŒ Ø¢Ù† Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ Ú©Ù„Ø§ÛŒÙ†Øª Ù…ÛŒâ€ŒÙØ±Ø³ØªÛŒÙ… Ø¨Ù‡ ØµÙˆØ±Øª Ø®Ø·ÙˆØ· SSE
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      const chunk = decoder.decode(value, { stream: true });

      // Ø¨Ø±Ø®ÛŒ Ø³Ø±ÙˆØ±Ù‡Ø§ÛŒ OpenAI chunkÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ "\n" ÛŒØ§ "data: ..." Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.
      // Ù…Ø§ Ù‡Ø± Ú†ÛŒØ²ÛŒ Ú©Ù‡ Ø¢Ù…Ø¯ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§ÛŒÙ†Øª Ø¨Ø§ Ù¾ÛŒØ´ÙˆÙ†Ø¯ data: Ù…ÛŒâ€ŒÙ†ÙˆÛŒØ³ÛŒÙ… ØªØ§ Ù‚Ø§Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§Ø´Ø¯.
      // (Ú©Ù„Ø§ÛŒÙ†Øª Ù‡Ù…Ø§Ù†Ù†Ø¯ Ù‚Ø¨Ù„ chunkÙ‡Ø§ Ø±Ø§ Ø®ÙˆØ§Ù‡Ø¯ Ø®ÙˆØ§Ù†Ø¯)
      res.write(chunk);
    }

    res.end();
  } catch (err) {
    console.error("Server error:", err);
    if (!res.headersSent) res.status(500).json({ error: "server_error" });
    else res.end();
  }
});

app.listen(PORT, () => {
  console.log(`ðŸš€ Server listening at http://localhost:${PORT}`);
});
